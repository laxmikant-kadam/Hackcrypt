"# Sutradhar ğŸš€

Sutradhar is an innovative AI-powered platform designed to make computers accessible to everyone, regardless of physical abilities or technical expertise. Leveraging advanced biometric technologies, computer vision, and natural language processing, Sutradhar empowers users to interact with computers through facial recognition, hand gestures, voice commands, and more.

## ğŸŒŸ Unique Selling Points (USPs)

- **Inclusive Accessibility**: Designed specifically for users with disabilities, elderly individuals, and those new to technology
- **Multi-Modal Interaction**: Seamlessly combines voice, gesture, facial, and touch inputs for natural, intuitive interaction
- **AI-Powered Intelligence**: Advanced AI capabilities providing personalized assistance and adaptive learning
- **Hardware Integration**: Seamless integration with physical devices like ESP32 for enhanced control
- **Open-Source & Customizable**: Fully open-source codebase allowing community contributions and easy customization
- **Real-Time Processing**: Low-latency computer vision and AI processing for responsive user experience

## âœ¨ Features

- ğŸ¤– **Jarvis AI Assistant**: Intelligent conversational AI for seamless interaction
- ğŸ‘¤ **Facial Recognition**: Advanced face detection and recognition capabilities
- âœ‹ **Hand Gesture Control**: Intuitive hand tracking for computer control
- ğŸ¤ **Voice Features**: Speech recognition and text-to-speech functionality
- ğŸ§  **Biometric Authentication**: Secure access through facial and retinal features
- ğŸ“± **Cross-Platform UI**: Modern React-based interface with responsive design
- ğŸ”§ **System Integration**: Control system stats, launch apps, and more
- ğŸŒ **Web Services**: Integrated weather, news, calendar, and search functionalities
- ğŸ“„ **PDF Reader**: Built-in PDF reading capabilities
- ğŸ® **Quiz Game**: Interactive quiz features for engagement
- ğŸ”³ **AR Button**: Augmented Reality interactive buttons for immersive control
- ğŸ§­ **Navigational Trigger**: Advanced navigation and action triggering system

## ğŸ› ï¸ Tech Stack

- **Backend**: Python Flask with OpenCV, MediaPipe, Google Generative AI
- **Frontend**: React + TypeScript + Vite + Tailwind CSS
- **AI/ML**: Computer vision, speech recognition, NLP
- **Deployment**: Docker + Docker Compose
- **Hardware Integration**: ESP32 support for physical button interactions

## ğŸ“‹ Prerequisites

- Docker and Docker Compose installed
- At least 4GB RAM recommended
- Webcam access for facial/hand recognition features
- Python 3.8+ (for local development)
- Node.js 16+ (for local development)

## ğŸš€ Getting Started

### Using Docker (Recommended)

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd sutradhar
   ```

2. **Start the application**:
   ```bash
   docker-compose up --build
   ```

3. **Access the application**:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:5000

### Local Development

#### Backend Setup
```bash
cd backend
pip install -r requirements.txt
python server.py
```

#### Frontend Setup
```bash
cd my-app
npm install
npm run dev
```

#### Hardware Server (Optional)
For ESP32 integration:
```bash
python hardwareserver.py
```

## ğŸ—ï¸ Project Structure

```
sutradhar/
â”œâ”€â”€ backend/              # Flask Python backend
â”‚   â”œâ”€â”€ app/             # Main application modules
â”‚   â”œâ”€â”€ features/        # AI features (facial, voice, hand tracking)
â”‚   â”œâ”€â”€ datasets/        # Training data and known faces
â”‚   â”œâ”€â”€ services/        # Email, weather, Jarvis services
â”‚   â””â”€â”€ Dockerfile       # Backend container config
â”œâ”€â”€ my-app/              # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # UI components (Jarvis, Biometric, etc.)
â”‚   â”‚   â”œâ”€â”€ api/         # API integration
â”‚   â”‚   â””â”€â”€ pages/       # Application pages
â”‚   â”œâ”€â”€ public/          # Static assets
â”‚   â””â”€â”€ Dockerfile       # Frontend container config
â”œâ”€â”€ docker-compose.yml   # Multi-container orchestration
â”œâ”€â”€ hardwareserver.py    # ESP32 hardware integration server
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

- Backend environment variables in `backend/.env`
- Configure API keys for Google Generative AI, weather services, etc.
- Frontend configuration in `my-app/`

## ğŸ¯ Usage

1. **Launch the application** using Docker Compose
2. **Access the web interface** at http://localhost:3000
3. **Enable camera permissions** for facial recognition features
4. **Use voice commands** or hand gestures to interact
5. **Explore Jarvis assistant** for AI-powered assistance

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with â¤ï¸ to make technology accessible to all
- Special thanks to the open-source community for amazing libraries

## ğŸ“ Support

For questions, issues, or feature requests:
- Open an issue in this repository
- Contact the maintainers

---

**Sutradhar** - Empowering everyone to harness the power of technology! ğŸŒŸ" 
